{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AeroFusion: Autonomous BLIMP Navigation and Sensor Integration Platform","text":""},{"location":"#1-repository-structure-review","title":"1. Repository Structure Review","text":"<p>Before diving into the project details, we reviewed the cloned template to understand how the folder structure translates to the website. We removed all markdown pages except for index.md to prepare the report. This clean setup ensures that our final website only displays the main home page, keeping the structure clear and uncluttered.</p>"},{"location":"#2-home-page","title":"2. Home Page","text":"<p>Project Name: </p> <p>AeroFusion: Autonomous BLIMP Navigation and Sensor Integration Platform</p> <p>Team Number: </p> <p>Team 03</p> <p>Team Members: </p> <ul> <li>Nihar Masurkar</li> <li>Prajjwal Dutta</li> <li>Sai Srinivas Tatwik Meesala</li> </ul> <p>Semester and Year: Spring 2025</p> <p>University, Class, and Professor:</p> <ul> <li>University: Arizona State University  </li> <li>Class: RAS 598: Experimentation and Deployment of Robotic Systems</li> <li>Professor: Dr. Daniel M. Aukes </li> </ul>"},{"location":"#3-project-plan","title":"3. Project Plan","text":""},{"location":"#31-high-level-concept-and-research-question","title":"3.1 High-Level Concept and Research Question","text":"<p>Our project aims to to develop an integrated, sensor-driven framework that enables an Biologically-inspired, Lighter-than-air, Instructional, Mechatronics Program (BLIMP) UAV to operate autonomously in dynamic and uncertain environments. The central research question is: \"How effectively can sensor data from various sensors (such as Time-of-Flight Sensor, IMU, Barometer, Camera) can be fused together to trajectory planning, and autonomous navigation capabilities of a hybrid robotic blimp system in dynamic environments?\"  The experiment involves using the UR5 to position the quadruped at a designated start point, triggering the quadruped to run in a specified direction, and collecting sensor data during its motion. We then broadcast this data to a server for analysis, comparing it with simulated data. The refined simulation results are subsequently applied back to the robot to evaluate improvements in performance.</p> <p> Figure 1: CAD Rendering of Biologically-inspired, Lighter-than-air, Instructional, Mechatronics Program (BLIMP) UAV</p>"},{"location":"#32-sensor-integration","title":"3.2 Sensor Integration","text":"<p>Sensor integration in this project is approached as a systematic and multi-layered process, ensuring that the rich dataset from each sensor is effectively harnessed across all stages of development\u2014from coding through testing to the final demonstration. In the code, sensor data is published on dedicated ROS 2 topics, where each sensor (IMU, barometer, GPS, Raspberry Pi camera, sonar, and LiDAR) continuously streams its specific measurements. This design facilitates a modular architecture where sensor outputs are processed both independently and as part of a sensor fusion algorithm, enhancing real-time decision-making and control. Various sensors would be integrated in the BLIMP structure to enable navigation autonomy such as:</p> <ul> <li>IMU: An inertial measurement unit that provides high-frequency data on orientation, angular velocity, and acceleration to ensure precise attitude estimation and dynamic stabilization.</li> <li>Barometer: A pressure sensor that measures atmospheric pressure changes to accurately determine altitude variations, which is critical for maintaining vertical stability.</li> <li>GPS: A global positioning module that delivers reliable geospatial coordinates and velocity information, essential for outdoor localization and navigation.</li> <li>Raspberry Pi Camera: A compact imaging device that captures high-resolution visual data for localization and goal detection, thereby enhancing situational awareness.</li> <li>Sonar: An ultrasonic sensor that emits sound waves to detect objects and measure distances in real-time, facilitating effective obstacle detection and collision avoidance.</li> <li>ToF Sensor (LiDAR): A laser-based sensor that generates detailed three-dimensional maps of the surrounding environment, significantly improving obstacle detection and spatial mapping.</li> </ul> <p>During testing, individual sensor outputs are validated using ROS 2 tools like rqt_plot and ros2 topic echo, ensuring that each sensor is correctly calibrated and operating within expected parameters. This stage not only verifies the performance of the sensors in isolation but also provides critical feedback for refining sensor fusion strategies. The testing phase includes both controlled indoor experiments and field trials, allowing the team to observe how sensor data influences the system\u2019s stability, localization accuracy, and obstacle detection in varying environments.</p> <p>In the final demonstration, the real-time integration of sensor data is pivotal. The IMU contributes to precise orientation control, while the barometer maintains altitude, and the GPS offers robust localization. Simultaneously, the Raspberry Pi camera supports visual goal detection and aids in dynamic decision-making, and the sonar along with LiDAR enhance the system's ability to detect and avoid obstacles. This cohesive sensor data integration not only drives the autonomous control loops\u2014enabling adaptive trajectory planning and responsive mode switching between manual and autonomous controls\u2014but also showcases the system\u2019s comprehensive ability to operate reliably in real-world, dynamic scenarios.</p>"},{"location":"#33-interaction-and-interface-development","title":"3.3 Interaction and Interface Development","text":"<p>The behavior of the robot is designed to be influenced through a dual-mode control strategy complemented by a comprehensive graphical user interface. In manual mode, users can directly adjust the robot\u2019s throttle, direction, and altitude via a joystick, allowing for precise, hands-on control. In autonomous mode, the robot employs trajectory planning algorithms based on goal positions detected by the onboard camera, with a dedicated joystick button facilitating seamless mode switching between manual and autonomous operations.</p> <p>For interfacing, we are developing a robust GUI based on ROS that serves multiple functions. It will provide real-time visualization of sensor data\u2014including IMU, barometer, GPS, camera, sonar, and LiDAR outputs\u2014ensuring that the operator has complete situational awareness. Additionally, the GUI will display the current control status (manual or autonomous), present a live camera feed with an overlay indicating goal detection, and log performance data for subsequent analysis. This design not only enables immediate interaction during operation but also supports detailed post-mission reviews.</p>"},{"location":"#34-control-and-autonomy","title":"3.4 Control and Autonomy","text":"<p>The proposed system integrates sensor feedback across both low-level control and high-level decision-making processes. In manual operation, user inputs via a joystick directly set parameters such as thrust, direction, and altitude. Conversely, during autonomous navigation, the Raspberry Pi Camera identifies goal positions that inform trajectory planning algorithms. In tandem, continuous feedback from the IMU and barometer maintains altitude stability by providing real-time orientation and pressure data. This sensor data is then fed into a dynamic feedback loop, where PID controllers perform immediate trajectory corrections, with plans to evolve towards model predictive control (MPC) for enhanced adaptive performance. Overall, by seamlessly connecting sensor inputs to both the controller and strategic decision layers, the system ensures robust and responsive behavior under varying operational conditions.</p>"},{"location":"#35-prepartion","title":"3.5 Prepartion","text":"<p>To achieve complete autonomy of the BLIMP, a comprehensive understanding of several interrelated technical areas. At a foundational level, proficiency in trajectory planning algorithms is essential for designing efficient navigation paths, while sensor fusion techniques are critical for integrating data from various sensors to achieve accurate state estimation. Additionally, expertise in ROS 2 GUI development is necessary to create an intuitive interface for real-time data visualization and system interaction.</p> <p>In terms of classroom topics, it would be beneficial for us if you would cover topics such as the principles and practical applications of PID controllers and Model Predictive Control (MPC) within ROS, as these control strategies underpin our approach to ensuring stable and responsive system behavior. Further, in-depth instruction on ROS2 GUI implementation will equip the team with the skills needed to develop a robust user interface.</p> <p>Understanding UAV control dynamics and the use of remote SSH to access the Raspberry Pi desktop environment are also important to effectively manage the system\u2019s operation and debugging processes. These areas of focus will collectively provide the technical foundation required to successfully integrate sensor data and advanced control algorithms into a cohesive autonomous system.</p>"},{"location":"#36-final-demonstration","title":"3.6 Final Demonstration","text":""},{"location":"#37-impact-of-the-work","title":"3.7 Impact of the Work","text":""},{"location":"#38-advising","title":"3.8 Advising","text":""},{"location":"#4-weekly-milestones-weeks-7-16","title":"4. Weekly Milestones (Weeks 7-16)","text":""},{"location":"second-page/","title":"Second Page","text":"<p>Things to discuss</p>"},{"location":"static/node_modules/mathjax/","title":"MathJax","text":""},{"location":"static/node_modules/mathjax/#beautiful-math-in-all-browsers","title":"Beautiful math in all browsers","text":"<p>MathJax is an open-source JavaScript display engine for LaTeX, MathML, and AsciiMath notation that works in all modern browsers.  It was designed with the goal of consolidating the recent advances in web technologies into a single, definitive, math-on-the-web platform supporting the major browsers and operating systems.  It requires no setup on the part of the user (no plugins to download or software to install), so the page author can write web documents that include mathematics and be confident that users will be able to view it naturally and easily.  Simply include MathJax and some mathematics in a web page, and MathJax does the rest.</p> <p>Some of the main features of MathJax include:</p> <ul> <li> <p>High-quality display of LaTeX, MathML, and AsciiMath notation in HTML pages</p> </li> <li> <p>Supported in most browsers with no plug-ins, extra fonts, or special   setup for the reader</p> </li> <li> <p>Easy for authors, flexible for publishers, extensible for developers</p> </li> <li> <p>Supports math accessibility, cut-and-paste interoperability, and other   advanced functionality</p> </li> <li> <p>Powerful API for integration with other web applications</p> </li> </ul> <p>See http://www.mathjax.org/ for additional details about MathJax, and https://docs.mathjax.org for the MathJax documentation.</p>"},{"location":"static/node_modules/mathjax/#mathjax-components","title":"MathJax Components","text":"<p>MathJax version 3 uses files called components that contain the various MathJax modules that you can include in your web pages or access on a server through NodeJS.  Some components combine all the pieces you need to run MathJax with one or more input formats and a particular output format, while other components are pieces that can be loaded on demand when needed, or by a configuration that specifies the pieces you want to combine in a custom way.  For usage instructions, see the MathJax documentation.</p> <p>Components provide a convenient packaging of MathJax's modules, but it is possible for you to form your own custom components, or to use MathJax's modules directly in a node application on a server.  There are web examples showing how to use MathJax in web pages and how to build your own components, and node examples illustrating how to use components in node applications or call MathJax modules directly.</p>"},{"location":"static/node_modules/mathjax/#whats-in-this-repository","title":"What's in this Repository","text":"<p>This repository contains only the component files for MathJax, not the source code for MathJax (which are available in a separate MathJax source repository).  These component files are the ones served by the CDNs that offer MathJax to the web.  In version 2, the files used on the web were also the source files for MathJax, but in version 3, the source files are no longer on the CDN, as they are not what are run in the browser.</p> <p>The components are stored in the <code>es5</code> directory, and are in ES5 format for the widest possible compatibility.  In the future, we may make an <code>es6</code> directory containing ES6 versions of the components.</p>"},{"location":"static/node_modules/mathjax/#installation-and-use","title":"Installation and Use","text":""},{"location":"static/node_modules/mathjax/#using-mathjax-components-from-a-cdn-on-the-web","title":"Using MathJax components from a CDN on the web","text":"<p>If you are loading MathJax from a CDN into a web page, there is no need to install anything.  Simply use a <code>script</code> tag that loads MathJax from the CDN.  E.g.,</p> <pre><code>&lt;script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"&gt;&lt;/script&gt;\n</code></pre> <p>See the MathJax documentation, the MathJax Web Demos, and the MathJax Component Repository for more information.</p>"},{"location":"static/node_modules/mathjax/#hosting-your-own-copy-of-the-mathjax-components","title":"Hosting your own copy of the MathJax Components","text":"<p>If you want to host MathJax from your own server, you can do so by installing the <code>mathjax</code> package using <code>npm</code> and moving the <code>es5</code> directory to an appropriate location on your server:</p> <pre><code>npm install mathjax@3\nmv node_modules/mathjax/es5 &lt;path-to-server-location&gt;/mathjax\n</code></pre> <p>Note that we are still making updates to version 2, so include <code>@3</code> when you install, since the latest chronological version may not be version 3.</p> <p>Alternatively, you can get the files via GitHub:</p> <pre><code>git clone https://github.com/mathjax/MathJax.git mj-tmp\nmv mj-tmp/es5 &lt;path-to-server-location&gt;/mathjax\nrm -rf mj-tmp\n</code></pre> <p>Then (in either case) you can use a script tag like the following:</p> <pre><code>&lt;script id=\"MathJax-script\" async src=\"&lt;url-to-your-site&gt;/mathjax/tex-chtml.js\"&gt;&lt;/script&gt;\n</code></pre> <p>where <code>&lt;url-to-your-site&gt;</code> is replaced by the URL to the location where you moved the MathJax files above.</p> <p>See the documentation for details.</p>"},{"location":"static/node_modules/mathjax/#using-mathjax-components-in-a-node-application","title":"Using MathJax components in a node application","text":"<p>To use MathJax components in a node application, install the <code>mathjax</code> package:</p> <pre><code>npm install mathjax@3\n</code></pre> <p>(we are still making updates to version 2, so you should include <code>@3</code> since the latest chronological version may not be version 3).</p> <p>Then require <code>mathjax</code> within your application:</p> <pre><code>require('mathjax').init({ ... }).then((MathJax) =&gt; { ... });\n</code></pre> <p>where the first <code>{ ... }</code> is a MathJax configuration, and the second <code>{ ... }</code> is the code to run after MathJax has been loaded.  E.g.</p> <pre><code>require('mathjax').init({\nloader: {load: ['input/tex', 'output/svg']}\n}).then((MathJax) =&gt; {\nconst svg = MathJax.tex2svg('\\\\frac{1}{x^2-1}', {display: true});\nconsole.log(MathJax.startup.adaptor.outerHTML(svg));\n}).catch((err) =&gt; console.log(err.message));\n</code></pre> <p>Note: this technique is for node-based application only, not for browser applications.  This method sets up an alternative DOM implementation, which you don't need in the browser, and tells MathJax to use node's <code>require()</code> command to load external modules.  This setup will not work properly in the browser, even if you webpack it or bundle it in other ways.</p> <p>See the documentation and the MathJax Node Repository for more details.</p>"},{"location":"static/node_modules/mathjax/#reducing-the-size-of-the-components-directory","title":"Reducing the Size of the Components Directory","text":"<p>Since the <code>es5</code> directory contains all the component files, so if you are only planning one use one configuration, you can reduce the size of the MathJax directory by removing unused components. For example, if you are using the <code>tex-chtml.js</code> component, then you can remove the <code>tex-mml-chtml.js</code>, <code>tex-svg.js</code>, <code>tex-mml-svg.js</code>, <code>tex-chtml-full.js</code>, and <code>tex-svg-full.js</code> configurations, which will save considerable space.  Indeed, you should be able to remove everything other than <code>tex-chtml.js</code>, and the <code>input/tex/extensions</code>, <code>output/chtml/fonts/woff-v2</code>, <code>adaptors</code>, <code>a11y</code>, and <code>sre</code> directories.  If you are using the results only on the web, you can remove <code>adaptors</code> as well.</p> <p>If you are not using A11Y support (e.g., speech generation, or semantic enrichment), then you can remove <code>a11y</code> and <code>sre</code> as well (though in this case you may need to disable the assistive tools in the MathJax contextual menu in order to avoid MathJax trying to load them when they aren't there).</p> <p>If you are using SVG rather than CommonHTML output (e.g., <code>tex-svg.js</code> rather than <code>tex-chtml.js</code>), you can remove the <code>output/chtml/fonts/woff-v2</code> directory.  If you are using MathML input rather than TeX (e.g., <code>mml-chtml.js</code> rather than <code>tex-chtml.js</code>), then you can remove <code>input/tex/extensions</code> as well.</p>"},{"location":"static/node_modules/mathjax/#the-component-files-and-pull-requests","title":"The Component Files and Pull Requests","text":"<p>The <code>es5</code> directory is generated automatically from the contents of the MathJax source repository.  You can rebuild the components using the command</p> <pre><code>npm run make-es5 --silent\n</code></pre> <p>Note that since the contents of this repository are generated automatically, you should not submit pull requests that modify the contents of the <code>es5</code> directory.  If you wish to submit a modification to MathJax, you should make a pull request in the MathJax source repository.</p>"},{"location":"static/node_modules/mathjax/#mathjax-community","title":"MathJax Community","text":"<p>The main MathJax website is http://www.mathjax.org, and it includes announcements and other important information.  A MathJax user forum for asking questions and getting assistance is hosted at Google, and the MathJax bug tracker is hosted at GitHub.</p> <p>Before reporting a bug, please check that it has not already been reported.  Also, please use the bug tracker (rather than the help forum) for reporting bugs, and use the user's forum (rather than the bug tracker) for questions about how to use MathJax.</p>"},{"location":"static/node_modules/mathjax/#mathjax-resources","title":"MathJax Resources","text":"<ul> <li>MathJax Documentation</li> <li>MathJax Components</li> <li>MathJax Source Code</li> <li>MathJax Web Examples</li> <li>MathJax Node Examples</li> <li>MathJax Bug Tracker</li> <li>MathJax Users' Group</li> </ul>"}]}